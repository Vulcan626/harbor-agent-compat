import os
import shlex
import json

from harbor.agents.installed.opencode import OpenCode
from harbor.agents.installed.base import ExecInput


# ------ Configs ------
OVERRIDE_CFG_PATH = "/tmp/harbor_opencode_override.json"
XDG_CFG_HOME = "/tmp/harbor_xdg_config"

BUILTIN_PROVIDERS = {
    "openai",
    "anthropic",
    "azure",
    "google",
    "xai",
    "mistral",
    "groq",
    "huggingface",
    "llama",
    "deepseek",
    "github-copilot",
    "amazon-bedrock",
}


def _normalize_base_url(url: str) -> str:
    url = url.strip().rstrip("/")
    if not url.endswith("/v1"):
        url = url + "/v1"
    return url


class OpenCode0(OpenCode):
    """
    OpenCode agent with safe support for custom OpenAI-compatible providers
    via provider-scoped baseURL override.
    """

    def __init__(self, base_url: str | None = None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.base_url = base_url or os.environ.get("OPENCODE_BASE_URL")

    @staticmethod
    def name() -> str:
        return "opencode0"

    def create_run_agent_commands(self, instruction: str) -> list[ExecInput]:
        if not self.model_name or "/" not in self.model_name:
            raise ValueError("Model name must be in the format provider/model")

        provider, model = self.model_name.split("/", 1)

        # ---------- Case 1: built-in provider ----------
        if provider in BUILTIN_PROVIDERS:
            # Delegate to official OpenCode behavior
            return super().create_run_agent_commands(instruction)

        # ---------- Case 2: custom provider (e.g. ppapi) ----------
        if not self.base_url:
            raise ValueError(
                f"Custom provider '{provider}' requires OPENCODE_BASE_URL to be set"
            )

        base_url = _normalize_base_url(self.base_url)

        # Build an OpenAI-compatible custom provider so OpenCode can resolve provider/model.
        small_model_id = (os.environ.get("OPENCODE_SMALL_MODEL") or "").strip()

        cfg = {
            "$schema": "https://opencode.ai/config.json",
            "provider": {
                provider: {
                    "npm": "@ai-sdk/openai-compatible",
                    "name": provider,
                    "options": {
                        "baseURL": base_url,
                        "apiKey": "{env:OPENAI_API_KEY}",
                    },
                    "models": {
                        model: {"name": model},
                    },
                }
            },
        }

        # If OPENCODE_SMALL_MODEL is provided, pin both model and small_model to this provider.
        if small_model_id:
            cfg["model"] = f"{provider}/{model}"
            cfg["small_model"] = f"{provider}/{small_model_id}"
            cfg["provider"][provider]["models"][small_model_id] = {"name": small_model_id}



        cfg_json = json.dumps(cfg, ensure_ascii=False, indent=2)

        escaped_instruction = shlex.quote(instruction)

        env = {
            # Reuse OpenAI-compatible auth path
            "OPENAI_API_KEY": os.environ.get("OPENAI_API_KEY", ""),
            "OPENCODE_CONFIG": OVERRIDE_CFG_PATH,
            "XDG_CONFIG_HOME": XDG_CFG_HOME,
            "OPENCODE_FAKE_VCS": "git",
        }

        # Write override config and execute opencode
        command = (
            "mkdir -p /logs/agent/opencode_config /logs/agent/opencode_logs; "
            f"mkdir -p {shlex.quote(XDG_CFG_HOME)}/opencode; "
            f"cat > {shlex.quote(OVERRIDE_CFG_PATH)} <<'__HARBOR_OPENCODE_JSON__'\n"
            f"{cfg_json}\n"
            "__HARBOR_OPENCODE_JSON__\n"
            f"cp -f {shlex.quote(OVERRIDE_CFG_PATH)} "
            "/logs/agent/opencode_config/opencode_override.json "
            "2>/dev/null || true; "
            f"opencode --model {provider}/{model} run --format=json "
            f"{escaped_instruction} "
            "2>&1 | tee /logs/agent/opencode.txt"
        )

        return [ExecInput(command=command, env=env)]
